{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b49819e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2767, 37)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"elections_feature_reduced.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38afd519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['winner', 'PostalAbbr', 'ub', 'fips', 'PST045214', 'PST120214',\n",
       "       'AGE135214', 'AGE295214', 'AGE775214', 'SEX255214', 'RHI125214',\n",
       "       'RHI325214', 'RHI425214', 'RHI525214', 'RHI625214', 'RHI725214',\n",
       "       'RHI825214', 'POP715213', 'POP645213', 'EDU635213', 'EDU685213',\n",
       "       'LFE305213', 'HSG096213', 'HSG495213', 'HSD410213', 'INC910213',\n",
       "       'BZA110213', 'BZA115213', 'SBO001207', 'SBO315207', 'SBO115207',\n",
       "       'SBO415207', 'SBO015207', 'WTN220207', 'RTN131207', 'LND110210',\n",
       "       'POP060210'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb19cb53",
   "metadata": {},
   "source": [
    "# Mean encoding of PostalAbbr feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f1e1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ml=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7599c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ml=data_ml.drop([\"fips\",'ub'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07d60751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner</th>\n",
       "      <th>PostalAbbr</th>\n",
       "      <th>PST045214</th>\n",
       "      <th>PST120214</th>\n",
       "      <th>AGE135214</th>\n",
       "      <th>AGE295214</th>\n",
       "      <th>AGE775214</th>\n",
       "      <th>SEX255214</th>\n",
       "      <th>RHI125214</th>\n",
       "      <th>RHI325214</th>\n",
       "      <th>...</th>\n",
       "      <th>BZA115213</th>\n",
       "      <th>SBO001207</th>\n",
       "      <th>SBO315207</th>\n",
       "      <th>SBO115207</th>\n",
       "      <th>SBO415207</th>\n",
       "      <th>SBO015207</th>\n",
       "      <th>WTN220207</th>\n",
       "      <th>RTN131207</th>\n",
       "      <th>LND110210</th>\n",
       "      <th>POP060210</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>24965</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>21.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>51.5</td>\n",
       "      <td>69.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1385</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0</td>\n",
       "      <td>2841</td>\n",
       "      <td>490.48</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>62486</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>26.7</td>\n",
       "      <td>13.5</td>\n",
       "      <td>51.5</td>\n",
       "      <td>79.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0</td>\n",
       "      <td>8808</td>\n",
       "      <td>655.12</td>\n",
       "      <td>94.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>33021</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>68.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>2944</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>59400</td>\n",
       "      <td>7749</td>\n",
       "      <td>449.50</td>\n",
       "      <td>73.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>426236</td>\n",
       "      <td>8.6</td>\n",
       "      <td>6.2</td>\n",
       "      <td>25.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>49.9</td>\n",
       "      <td>92.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>42344</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.4</td>\n",
       "      <td>6006918</td>\n",
       "      <td>15720</td>\n",
       "      <td>1052.58</td>\n",
       "      <td>372.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3861</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>48.5</td>\n",
       "      <td>96.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0</td>\n",
       "      <td>5627</td>\n",
       "      <td>1363.06</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   winner  PostalAbbr  PST045214  PST120214  AGE135214  AGE295214  AGE775214  \\\n",
       "0       1    0.695652      24965       -1.8        5.4       21.5       19.4   \n",
       "1       1    0.606557      62486        1.2        7.1       26.7       13.5   \n",
       "2       1    0.736842      33021       -0.4        6.0       20.9       21.3   \n",
       "3       1    1.000000     426236        8.6        6.2       25.1       12.6   \n",
       "4       1    1.000000       3861       -2.9        4.2       17.0       24.9   \n",
       "\n",
       "   SEX255214  RHI125214  RHI325214  ...  BZA115213  SBO001207  SBO315207  \\\n",
       "0       51.5       69.7        0.3  ...        2.7       1385       19.1   \n",
       "1       51.5       79.6        0.3  ...        3.1       4289        0.0   \n",
       "2       51.3       68.8        0.7  ...       -0.6       2944        6.0   \n",
       "3       49.9       92.4        0.8  ...        2.2      42344        0.4   \n",
       "4       48.5       96.4        1.0  ...        7.3        492        0.0   \n",
       "\n",
       "   SBO115207  SBO415207  SBO015207  WTN220207  RTN131207  LND110210  POP060210  \n",
       "0        0.0        0.0       33.4          0       2841     490.48       51.8  \n",
       "1        0.0        1.4       25.4          0       8808     655.12       94.3  \n",
       "2        0.0        0.0       23.1      59400       7749     449.50       73.8  \n",
       "3        1.0        2.1       25.4    6006918      15720    1052.58      372.8  \n",
       "4        0.0        0.0       18.1          0       5627    1363.06        2.9  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mean_encoded_PostalAbbr = data_ml.groupby(['PostalAbbr'])['winner'].mean().to_dict()\n",
    "\n",
    "data_ml['PostalAbbr'] = data_ml['PostalAbbr'].map(Mean_encoded_PostalAbbr)\n",
    "\n",
    "data_ml.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a69386e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2767, 35)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f55ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pandas.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f5f67",
   "metadata": {},
   "source": [
    "# Separating target from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3bbe508",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data_ml[\"winner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44f423ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_ml.drop([\"winner\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b23808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X[X.isna().any(axis=1)]\n",
    "X.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98994dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5468e8",
   "metadata": {},
   "source": [
    "# Standardization for Logit Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b130b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler() \n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda4624",
   "metadata": {},
   "source": [
    "**Splitting data into train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f63a51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit_model=LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "logit_model.fit(X_train,y_train)\n",
    "y_pred=logit_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6259c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bce367c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8303249097472925\n",
      "Precision is:  0.8463541666666666\n",
      "Recall is:  0.9027777777777778\n",
      "f1 score is:  0.8736559139784946\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99fd94b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74       194\n",
      "           1       0.85      0.90      0.87       360\n",
      "\n",
      "    accuracy                           0.83       554\n",
      "   macro avg       0.82      0.80      0.81       554\n",
      "weighted avg       0.83      0.83      0.83       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_actual = pd.Series(y_test)\n",
    "y_predicted = pd.Series(y_pred)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6050f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135,  59],\n",
       "       [ 35, 325]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004aaed2",
   "metadata": {},
   "source": [
    "### Naive Bayes with standardized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "809019dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nv = GaussianNB()\n",
    "nv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd23c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.7436823104693141\n",
      "Precision is:  0.7400881057268722\n",
      "Recall is:  0.9333333333333333\n",
      "f1 score is:  0.8255528255528255\n"
     ]
    }
   ],
   "source": [
    "y_pred = nv.predict(X_test)\n",
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87dcc770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 76, 118],\n",
       "       [ 24, 336]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088b88c",
   "metadata": {},
   "source": [
    "# Normalization for K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1593520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) \n",
    "X_scaled_nor = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfcd15f",
   "metadata": {},
   "source": [
    "**Splitting data into train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "069c79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_scaled_nor,y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c89aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "acc_values=[]\n",
    "neighbors = np.arange(3,15)\n",
    "for k in neighbors:\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k, metric='minkowski')\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    acc=accuracy_score(y_test,y_pred)\n",
    "    acc_values.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6db2734c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8158844765342961,\n",
       " 0.8231046931407943,\n",
       " 0.8158844765342961,\n",
       " 0.8086642599277978,\n",
       " 0.8068592057761733,\n",
       " 0.8158844765342961,\n",
       " 0.8104693140794224,\n",
       " 0.8086642599277978,\n",
       " 0.8032490974729242,\n",
       " 0.8104693140794224,\n",
       " 0.8050541516245487,\n",
       " 0.8068592057761733]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82e28f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(neighbors,acc_values, 'o-')\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8675736",
   "metadata": {},
   "source": [
    "**k=4 gives the highest value of accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5fd8a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=4, metric='minkowski')\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ba79338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8231046931407943\n",
      "Precision is:  0.8679775280898876\n",
      "Recall is:  0.8583333333333333\n",
      "f1 score is:  0.8631284916201116\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc63d573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[147,  47],\n",
       "       [ 51, 309]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3258e0b3",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf3d10a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_linear= SVC(kernel='linear')\n",
    "svm_linear.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f4cbd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svm_linear.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4addefa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8393501805054152\n",
      "Precision is:  0.8501291989664083\n",
      "Recall is:  0.9138888888888889\n",
      "f1 score is:  0.8808567603748327\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4237b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[136,  58],\n",
       "       [ 31, 329]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc33eb",
   "metadata": {},
   "source": [
    "# Radial SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7fe653b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_radial=SVC(kernel='rbf')\n",
    "svm_radial.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "600477b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=svm_radial.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d4d1739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8267148014440433\n",
      "Precision is:  0.8367346938775511\n",
      "Recall is:  0.9111111111111111\n",
      "f1 score is:  0.8723404255319148\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed5b17b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[130,  64],\n",
       "       [ 32, 328]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273777a4",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb647b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af1f4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8483754512635379\n",
      "Precision is:  0.8387896825396826\n",
      "Recall is:  0.8227233676975945\n",
      "f1 score is:  0.8295759173807955\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred, average='macro'))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred,average='macro'))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred,average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcf6f436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143,  51],\n",
       "       [ 33, 327]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b452edbf",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05183a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_nor=pd.DataFrame(X_scaled_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9d46a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pandas.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "729eb1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.211794\n",
       "13    0.055905\n",
       "7     0.051828\n",
       "19    0.043102\n",
       "20    0.035449\n",
       "22    0.030431\n",
       "21    0.028939\n",
       "33    0.027780\n",
       "17    0.026797\n",
       "12    0.025750\n",
       "25    0.025683\n",
       "23    0.025075\n",
       "2     0.025066\n",
       "4     0.025062\n",
       "8     0.024351\n",
       "1     0.024040\n",
       "32    0.023864\n",
       "11    0.023631\n",
       "5     0.022577\n",
       "16    0.022441\n",
       "24    0.020679\n",
       "14    0.020565\n",
       "31    0.020241\n",
       "30    0.020152\n",
       "6     0.018494\n",
       "18    0.018337\n",
       "15    0.018093\n",
       "3     0.017179\n",
       "9     0.016502\n",
       "29    0.016362\n",
       "26    0.013776\n",
       "28    0.008558\n",
       "27    0.006664\n",
       "10    0.004832\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(rf.feature_importances_,index=X_scaled_nor.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae330db",
   "metadata": {},
   "source": [
    "### Trying Logistic Regression on Normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d31bf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit_model=LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "logit_model.fit(X_train,y_train)\n",
    "y_pred=logit_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dfa9739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8321299638989169\n",
      "Precision is:  0.8431876606683805\n",
      "Recall is:  0.9111111111111111\n",
      "f1 score is:  0.8758344459279038\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c48fe8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133,  61],\n",
       "       [ 32, 328]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c61827",
   "metadata": {},
   "source": [
    "**THis is pretty much the same accuracy as seen when using standardization, except for 1 less misclassification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4102ec7d",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8e53bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nv = GaussianNB()\n",
    "nv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78f85d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7436823104693141"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nv.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29e4c7",
   "metadata": {},
   "source": [
    "**The Naive Bayes classifier yields a poorer accuracy score than the non-probabilistic classifiers above**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83025cf5",
   "metadata": {},
   "source": [
    "## The important observations upon using mean encoding instead of dummy encoding are that:\n",
    "\n",
    "## 1.The performance of all algorithms except Logistic Regression has improved. But the performance of Logistic Regression algorithm has diminished.\n",
    "\n",
    "## 2.The accuracy of the Random Forest algorithm has improved from 0.8122 to 0.8483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd5523a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_method_name = ['LogisticReg and Normalization', 'Logistic Reg and Standardization', 'RandomForest and Normalization', 'SVM(linear) and normalization']\n",
    "accuracy_ohe_nopca = [0.851, 0.8501 , 0.812 , 0.846]\n",
    "accuracy_ohe_pca = [0, 0.8357 , 0.8086 , 0.8339]\n",
    "accuracy_meanenc_nopca = [0.8321, 0.8303 , 0.8483 , 0.8393]\n",
    "accuracy_meanenc_pca = [0, 0.8357 , 0.8068 , 0.8411]\n",
    "zipped = list(zip(algo_method_name, accuracy_ohe_nopca, accuracy_ohe_pca, accuracy_meanenc_nopca, accuracy_meanenc_pca))\n",
    "df = pd.DataFrame(zipped, columns=['Algorithm and method', 'OHE w/o PCA', 'OHE PCA', 'MeanEnc w/o PCA', 'MeanEnc PCA'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9da04904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm and method</th>\n",
       "      <th>OHE w/o PCA</th>\n",
       "      <th>OHE PCA</th>\n",
       "      <th>MeanEnc w/o PCA</th>\n",
       "      <th>MeanEnc PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticReg and Normalization</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8321</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Reg and Standardization</td>\n",
       "      <td>0.8501</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>0.8303</td>\n",
       "      <td>0.8357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest and Normalization</td>\n",
       "      <td>0.8120</td>\n",
       "      <td>0.8086</td>\n",
       "      <td>0.8483</td>\n",
       "      <td>0.8068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM(linear) and normalization</td>\n",
       "      <td>0.8460</td>\n",
       "      <td>0.8339</td>\n",
       "      <td>0.8393</td>\n",
       "      <td>0.8411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Algorithm and method  OHE w/o PCA  OHE PCA  MeanEnc w/o PCA  \\\n",
       "0     LogisticReg and Normalization       0.8510   0.0000           0.8321   \n",
       "1  Logistic Reg and Standardization       0.8501   0.8357           0.8303   \n",
       "2    RandomForest and Normalization       0.8120   0.8086           0.8483   \n",
       "3     SVM(linear) and normalization       0.8460   0.8339           0.8393   \n",
       "\n",
       "   MeanEnc PCA  \n",
       "0       0.0000  \n",
       "1       0.8357  \n",
       "2       0.8068  \n",
       "3       0.8411  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fcfbc1",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9050d34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12cb5dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'sqrt',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 0.1,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 50,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Run GridSearch to tune the hyper-parameter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "k_fold_cv = 5 # Stratified 5-fold cross validation\n",
    "grid_params = {\n",
    " \"n_estimators\" : [10,50],\n",
    " \"max_features\" : [\"auto\", \"sqrt\"],\n",
    " \"bootstrap\" : [False],\n",
    " \"criterion\" : ['gini','entropy'],\n",
    "# \"splitter\" : ['best','random'],\n",
    " \"min_samples_split\" : [0.1,0.2,0.3,0.4,0.5]\n",
    "}\n",
    "grid = GridSearchCV(rfc, param_grid=grid_params, cv=k_fold_cv, \n",
    " n_jobs = 1, verbose = 0, return_train_score=True)\n",
    "model = grid.fit(X_train, y_train)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(model.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f75dbc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper parameter: {'bootstrap': False, 'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_split': 0.1, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print('Best hyper parameter:', grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c286fa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best train score: 0.8283025034983605\n"
     ]
    }
   ],
   "source": [
    "print('Best train score:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c28e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8212996389891697\n",
      "Precision is:  0.8536585365853658\n",
      "Recall is:  0.875\n",
      "f1 score is:  0.8641975308641976\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d29b392b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[140,  54],\n",
       "       [ 45, 315]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39415951",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cfb5d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    }
   ],
   "source": [
    "# Run RandomizedSearchCV to tune the hyper-parameter\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rfc=RandomForestClassifier()\n",
    "k_fold_cv = 5 # Stratified 5-fold cross validation\n",
    "params = {\n",
    "    \"max_depth\" : [6,9,12,None],\n",
    " \"n_estimators\" : [10,50,100,150],\n",
    " \"max_features\" : [\"auto\", \"log2\", \"sqrt\"],\n",
    " \"bootstrap\" : [True, False],\n",
    " \"criterion\" : ['gini','entropy'],\n",
    "# \"splitter\" : ['best','random'],\n",
    " \"min_samples_split\" : [0.1,0.2,0.3,0.4,0.5]\n",
    " }\n",
    "random = RandomizedSearchCV(rfc, param_distributions=params, cv=k_fold_cv,\n",
    " n_iter = 5, scoring='accuracy',verbose=2, random_state=42,\n",
    " n_jobs=-1, return_train_score=True)\n",
    "model=random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d02ec0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper parameter: {'n_estimators': 100, 'min_samples_split': 0.1, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "print('Best hyper parameter:', random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b40378bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': 9,\n",
      " 'max_features': 'sqrt',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 0.1,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': None,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(model.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfd3ce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best train score: 0.826038017221127\n"
     ]
    }
   ],
   "source": [
    "print('Best train score:', random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0085a326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8122743682310469\n",
      "Precision is:  0.8368421052631579\n",
      "Recall is:  0.8833333333333333\n",
      "f1 score is:  0.8594594594594595\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e5a3a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[132,  62],\n",
       "       [ 42, 318]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc9837",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "937a145d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Random Search \n",
      "The best estimator across ALL searched params: GradientBoostingClassifier(learning_rate=0.07760012769115099, max_depth=9,\n",
      "                           n_estimators=891, subsample=0.7554964325357525)\n",
      "The best score across ALL searched params: 0.8508830168636303\n",
      "The best parameters across ALL searched params: {'learning_rate': 0.07760012769115099, 'max_depth': 9, 'n_estimators': 891, 'subsample': 0.7554964325357525}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "model = GradientBoostingClassifier()\n",
    "parameters = {\"learning_rate\": sp_randFloat(),\n",
    "                  \"subsample\"    : sp_randFloat(),\n",
    "                  \"n_estimators\" : sp_randInt(100, 1000),\n",
    "                  \"max_depth\"    : sp_randInt(4, 10)\n",
    "                 }\n",
    "randm_XGB = RandomizedSearchCV(estimator=model, param_distributions = parameters,\n",
    "                               cv = 5, n_iter = 10, n_jobs=-1)\n",
    "randm_XGB.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"The best estimator across ALL searched params:\", randm_XGB.best_estimator_)\n",
    "print(\"The best score across ALL searched params:\", randm_XGB.best_score_)\n",
    "print(\"The best parameters across ALL searched params:\", randm_XGB.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e72a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=randm_XGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de11aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8429602888086642\n",
      "Precision is:  0.8491048593350383\n",
      "Recall is:  0.9222222222222223\n",
      "f1 score is:  0.8841544607190414\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d25f955a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135,  59],\n",
       "       [ 28, 332]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d2cf5927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0,\n",
      " 'criterion': 'friedman_mse',\n",
      " 'init': None,\n",
      " 'learning_rate': 0.07760012769115099,\n",
      " 'loss': 'deviance',\n",
      " 'max_depth': 9,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 891,\n",
      " 'n_iter_no_change': None,\n",
      " 'random_state': None,\n",
      " 'subsample': 0.7554964325357525,\n",
      " 'tol': 0.0001,\n",
      " 'validation_fraction': 0.1,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(randm_XGB.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf41fd7",
   "metadata": {},
   "source": [
    "## XtremeGradientBoostingClassifier with RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87c05c04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dilip\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:45:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Results from Random Search \n",
      "The best estimator across ALL searched params: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.3,\n",
      "              enable_categorical=False, gamma=0.0, gpu_id=-1,\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.05, max_delta_step=0, max_depth=12,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=826, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              subsample=0.40419925222818365, tree_method='exact',\n",
      "              validate_parameters=1, verbosity=None)\n",
      "The best score across ALL searched params: 0.837779230462805\n",
      "The best parameters across ALL searched params: {'colsample_bytree': 0.3, 'gamma': 0.0, 'learning_rate': 0.05, 'max_depth': 12, 'min_child_weight': 1, 'n_estimators': 826, 'subsample': 0.40419925222818365}\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "model = xgboost.XGBClassifier()\n",
    "parameters = {\"learning_rate\": [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    "                  \"subsample\"    : sp_randFloat(),\n",
    "                  \"n_estimators\" : sp_randInt(100, 1000),\n",
    "                  \"max_depth\"    : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "                  \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "                  \"gamma\": [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "                  \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "                 }\n",
    "randm_XGB1 = RandomizedSearchCV(estimator=model, param_distributions = parameters,\n",
    "                               cv = 5, n_iter = 10, n_jobs=-1)\n",
    "randm_XGB1.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"The best estimator across ALL searched params:\", randm_XGB1.best_estimator_)\n",
    "print(\"The best score across ALL searched params:\", randm_XGB1.best_score_)\n",
    "print(\"The best parameters across ALL searched params:\", randm_XGB1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a105d119",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=randm_XGB1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efe7eb63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8321299638989169\n",
      "Precision is:  0.8414322250639387\n",
      "Recall is:  0.9138888888888889\n",
      "f1 score is:  0.8761651131824234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f67c5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[132,  62],\n",
       "       [ 31, 329]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb19bc02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5,\n",
      " 'booster': 'gbtree',\n",
      " 'colsample_bylevel': 1,\n",
      " 'colsample_bynode': 1,\n",
      " 'colsample_bytree': 0.3,\n",
      " 'enable_categorical': False,\n",
      " 'gamma': 0.0,\n",
      " 'gpu_id': -1,\n",
      " 'importance_type': None,\n",
      " 'interaction_constraints': '',\n",
      " 'learning_rate': 0.05,\n",
      " 'max_delta_step': 0,\n",
      " 'max_depth': 12,\n",
      " 'min_child_weight': 1,\n",
      " 'missing': nan,\n",
      " 'monotone_constraints': '()',\n",
      " 'n_estimators': 826,\n",
      " 'n_jobs': 8,\n",
      " 'num_parallel_tree': 1,\n",
      " 'objective': 'binary:logistic',\n",
      " 'predictor': 'auto',\n",
      " 'random_state': 0,\n",
      " 'reg_alpha': 0,\n",
      " 'reg_lambda': 1,\n",
      " 'scale_pos_weight': 1,\n",
      " 'subsample': 0.40419925222818365,\n",
      " 'tree_method': 'exact',\n",
      " 'use_label_encoder': True,\n",
      " 'validate_parameters': 1,\n",
      " 'verbosity': None}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(randm_XGB1.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd86f04e",
   "metadata": {},
   "source": [
    "## Logistic Regression with RandomSearchCV (using the standardized data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d3d0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_scaled,y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9c2b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit_model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "773f8e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_model.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f448fcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dilip\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.8269338  0.79712164 0.82783878        nan 0.82783878]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dilip\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the train scores are non-finite: [0.83935929 0.80241773 0.83766444        nan 0.83777737]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dilip\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "k_fold_cv = 5 # Stratified 5-fold cross validation\n",
    "params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'max_iter': list(range(100,800,100)),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    " }\n",
    "random = RandomizedSearchCV(logit_model, param_distributions=params, cv=k_fold_cv,\n",
    " n_iter = 5, scoring='accuracy',verbose=2, random_state=42,\n",
    " n_jobs=-1, return_train_score=True)\n",
    "model=random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5208ae9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper parameter: {'solver': 'saga', 'penalty': 'l1', 'max_iter': 200, 'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "print('Best hyper parameter:', random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7f937193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best train score: 0.8278387791998201\n"
     ]
    }
   ],
   "source": [
    "print('Best train score:', random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "224ecd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000,\n",
      " 'class_weight': None,\n",
      " 'dual': False,\n",
      " 'fit_intercept': True,\n",
      " 'intercept_scaling': 1,\n",
      " 'l1_ratio': None,\n",
      " 'max_iter': 200,\n",
      " 'multi_class': 'auto',\n",
      " 'n_jobs': None,\n",
      " 'penalty': 'l1',\n",
      " 'random_state': None,\n",
      " 'solver': 'saga',\n",
      " 'tol': 0.0001,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "pprint(model.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07dfef02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8429602888086642\n",
      "Precision is:  0.8582677165354331\n",
      "Recall is:  0.9083333333333333\n",
      "f1 score is:  0.8825910931174088\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "49d682b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[140,  54],\n",
       "       [ 33, 327]], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5223b699",
   "metadata": {},
   "source": [
    "## Removing one feature, which gave low feature_importance_ score earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e4600db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_nor_FeRe=X_scaled_nor.drop([10],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "840dd4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_scaled_nor_FeRe,y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb365d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dilip\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:11:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Results from Random Search \n",
      "The best estimator across ALL searched params: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.7,\n",
      "              enable_categorical=False, gamma=0.3, gpu_id=-1,\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=262, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              subsample=0.79876164423499, tree_method='exact',\n",
      "              validate_parameters=1, verbosity=None)\n",
      "The best score across ALL searched params: 0.8495235079619624\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "model = xgboost.XGBClassifier()\n",
    "parameters = {\"learning_rate\": [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    "                  \"subsample\"    : sp_randFloat(),\n",
    "                  \"n_estimators\" : sp_randInt(100, 1000),\n",
    "                  \"max_depth\"    : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "                  \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "                  \"gamma\": [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "                  \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "                 }\n",
    "randm_XGB2 = RandomizedSearchCV(estimator=model, param_distributions = parameters,\n",
    "                               cv = 5, n_iter = 10, n_jobs=-1)\n",
    "randm_XGB2.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"The best estimator across ALL searched params:\", randm_XGB2.best_estimator_)\n",
    "print(\"The best score across ALL searched params:\", randm_XGB2.best_score_)\n",
    "#print(\"The best parameters across ALL searched params:\", randm_XGB2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c21f6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8411552346570397\n",
      "Precision is:  0.8578947368421053\n",
      "Recall is:  0.9055555555555556\n",
      "f1 score is:  0.8810810810810811\n"
     ]
    }
   ],
   "source": [
    "y_pred=randm_XGB2.predict(X_test)\n",
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2878ece7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[140,  54],\n",
       "       [ 34, 326]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08511859",
   "metadata": {},
   "source": [
    "### Trying RandomForestClassifier instead of XGB and using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06af2ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best hyper parameter: {'n_estimators': 100, 'min_samples_split': 0.1, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'bootstrap': True}\n",
      "Best train score: 0.8260400600594465\n",
      "Accuracy is:  0.8231046931407943\n",
      "Precision is:  0.8447368421052631\n",
      "Recall is:  0.8916666666666667\n",
      "f1 score is:  0.8675675675675676\n"
     ]
    }
   ],
   "source": [
    "# Run RandomizedSearchCV to tune the hyper-parameter\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "k_fold_cv = 5 # Stratified 5-fold cross validation\n",
    "params = {\n",
    "    \"max_depth\" : [6,9,12,None],\n",
    " \"n_estimators\" : [10,50,100,150],\n",
    " \"max_features\" : [\"auto\", \"log2\", \"sqrt\"],\n",
    " \"bootstrap\" : [True, False],\n",
    " \"criterion\" : ['gini','entropy'],\n",
    "# \"splitter\" : ['best','random'],\n",
    " \"min_samples_split\" : [0.1,0.2,0.3,0.4,0.5]\n",
    " }\n",
    "random = RandomizedSearchCV(rfc, param_distributions=params, cv=k_fold_cv,\n",
    " n_iter = 5, scoring='accuracy',verbose=2, random_state=42,\n",
    " n_jobs=-1, return_train_score=True)\n",
    "model=random.fit(X_train, y_train)\n",
    "print('Best hyper parameter:', random.best_params_)\n",
    "print('Best train score:', random.best_score_)\n",
    "y_pred=model.predict(X_test)\n",
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58253a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135,  59],\n",
       "       [ 39, 321]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea5b1f7",
   "metadata": {},
   "source": [
    "### Trying again, by dropping one more feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6135c11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.373464</td>\n",
       "      <td>0.330508</td>\n",
       "      <td>0.425982</td>\n",
       "      <td>0.313525</td>\n",
       "      <td>0.801498</td>\n",
       "      <td>0.665537</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.687958</td>\n",
       "      <td>0.791837</td>\n",
       "      <td>0.019493</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.126404</td>\n",
       "      <td>0.524242</td>\n",
       "      <td>0.069119</td>\n",
       "      <td>0.062814</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.173092</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.407021</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.286357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035161</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.001571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.447174</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>0.583082</td>\n",
       "      <td>0.192623</td>\n",
       "      <td>0.801498</td>\n",
       "      <td>0.777401</td>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>0.044218</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.782199</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.021442</td>\n",
       "      <td>0.501852</td>\n",
       "      <td>0.098315</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.075808</td>\n",
       "      <td>0.059908</td>\n",
       "      <td>0.006963</td>\n",
       "      <td>0.206557</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>0.409216</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017949</td>\n",
       "      <td>0.451957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109010</td>\n",
       "      <td>0.032567</td>\n",
       "      <td>0.002863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.407862</td>\n",
       "      <td>0.381356</td>\n",
       "      <td>0.407855</td>\n",
       "      <td>0.352459</td>\n",
       "      <td>0.794007</td>\n",
       "      <td>0.655367</td>\n",
       "      <td>0.008121</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.054422</td>\n",
       "      <td>0.091004</td>\n",
       "      <td>0.607330</td>\n",
       "      <td>0.863265</td>\n",
       "      <td>0.136452</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.196629</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.132558</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.259186</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.388919</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.089955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.411032</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.095903</td>\n",
       "      <td>0.022314</td>\n",
       "      <td>0.002240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042124</td>\n",
       "      <td>0.628993</td>\n",
       "      <td>0.398305</td>\n",
       "      <td>0.534743</td>\n",
       "      <td>0.174180</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.922034</td>\n",
       "      <td>0.009281</td>\n",
       "      <td>0.061321</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>0.078452</td>\n",
       "      <td>0.862827</td>\n",
       "      <td>0.646939</td>\n",
       "      <td>0.115010</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.460674</td>\n",
       "      <td>0.296970</td>\n",
       "      <td>0.187291</td>\n",
       "      <td>0.166089</td>\n",
       "      <td>0.046920</td>\n",
       "      <td>0.348672</td>\n",
       "      <td>0.046001</td>\n",
       "      <td>0.404279</td>\n",
       "      <td>0.040445</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>0.451957</td>\n",
       "      <td>0.029234</td>\n",
       "      <td>0.194554</td>\n",
       "      <td>0.052385</td>\n",
       "      <td>0.011327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.346437</td>\n",
       "      <td>0.228814</td>\n",
       "      <td>0.290030</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.689139</td>\n",
       "      <td>0.967232</td>\n",
       "      <td>0.011601</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.031381</td>\n",
       "      <td>0.947644</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.019493</td>\n",
       "      <td>0.885185</td>\n",
       "      <td>0.262640</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>0.052397</td>\n",
       "      <td>0.129094</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.237554</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.432255</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069641</td>\n",
       "      <td>0.067867</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.695652  0.002459  0.373464  0.330508  0.425982  0.313525  0.801498   \n",
       "1  0.606557  0.006168  0.447174  0.474576  0.583082  0.192623  0.801498   \n",
       "2  0.736842  0.003256  0.407862  0.381356  0.407855  0.352459  0.794007   \n",
       "3  1.000000  0.042124  0.628993  0.398305  0.534743  0.174180  0.741573   \n",
       "4  1.000000  0.000373  0.346437  0.228814  0.290030  0.426230  0.689139   \n",
       "\n",
       "         7         8         9         11        12        13        14  \\\n",
       "0  0.665537  0.003480  0.009434  0.040816  0.010460  0.687958  0.791837   \n",
       "1  0.777401  0.003480  0.009434  0.044218  0.020921  0.782199  0.728571   \n",
       "2  0.655367  0.008121  0.016509  0.054422  0.091004  0.607330  0.863265   \n",
       "3  0.922034  0.009281  0.061321  0.091837  0.078452  0.862827  0.646939   \n",
       "4  0.967232  0.011601  0.011792  0.061224  0.031381  0.947644  0.765306   \n",
       "\n",
       "         15        16        17        18        19        20        21  \\\n",
       "0  0.019493  0.588889  0.126404  0.524242  0.069119  0.062814  0.003026   \n",
       "1  0.021442  0.501852  0.098315  0.563636  0.075808  0.059908  0.006963   \n",
       "2  0.136452  0.611111  0.196629  0.345455  0.057971  0.132558  0.004427   \n",
       "3  0.115010  0.900000  0.460674  0.296970  0.187291  0.166089  0.046920   \n",
       "4  0.019493  0.885185  0.262640  0.287879  0.052397  0.129094  0.000518   \n",
       "\n",
       "         22        23        24        25        26        27        28  \\\n",
       "0  0.173092  0.001155  0.407021  0.001323  0.286357  0.000000  0.000000   \n",
       "1  0.206557  0.003463  0.409216  0.004097  0.000000  0.000000  0.017949   \n",
       "2  0.259186  0.002310  0.388919  0.002812  0.089955  0.000000  0.000000   \n",
       "3  0.348672  0.046001  0.404279  0.040445  0.005997  0.018182  0.026923   \n",
       "4  0.237554  0.000120  0.432255  0.000470  0.000000  0.000000  0.000000   \n",
       "\n",
       "         29        30        31        32        33  \n",
       "0  0.594306  0.000000  0.035161  0.024357  0.001571  \n",
       "1  0.451957  0.000000  0.109010  0.032567  0.002863  \n",
       "2  0.411032  0.000289  0.095903  0.022314  0.002240  \n",
       "3  0.451957  0.029234  0.194554  0.052385  0.011327  \n",
       "4  0.322064  0.000000  0.069641  0.067867  0.000085  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_nor_FeRe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d4e74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_nor_FeRe=X_scaled_nor.drop([27],axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4aef0f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_scaled_nor_FeRe,y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a6e7fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dilip\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:16:42] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " Results from Random Search \n",
      "The best estimator across ALL searched params: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.5,\n",
      "              enable_categorical=False, gamma=0.1, gpu_id=-1,\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.15, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=779, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              subsample=0.8939786570789522, tree_method='exact',\n",
      "              validate_parameters=1, verbosity=None)\n",
      "The best score across ALL searched params: 0.8468218542843428\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "model = xgboost.XGBClassifier()\n",
    "parameters = {\"learning_rate\": [0.05,0.10,0.15,0.20,0.25,0.30],\n",
    "                  \"subsample\"    : sp_randFloat(),\n",
    "                  \"n_estimators\" : sp_randInt(100, 1000),\n",
    "                  \"max_depth\"    : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "                  \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "                  \"gamma\": [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    "                  \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "                 }\n",
    "randm_XGB3 = RandomizedSearchCV(estimator=model, param_distributions = parameters,\n",
    "                               cv = 5, n_iter = 10, n_jobs=-1)\n",
    "randm_XGB3.fit(X_train, y_train)\n",
    "\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"The best estimator across ALL searched params:\", randm_XGB3.best_estimator_)\n",
    "print(\"The best score across ALL searched params:\", randm_XGB3.best_score_)\n",
    "#print(\"The best parameters across ALL searched params:\", randm_XGB3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f19b776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8357400722021661\n",
      "Precision is:  0.8530183727034121\n",
      "Recall is:  0.9027777777777778\n",
      "f1 score is:  0.8771929824561404\n"
     ]
    }
   ],
   "source": [
    "y_pred=randm_XGB3.predict(X_test)\n",
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3779467b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[138,  56],\n",
       "       [ 35, 325]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012db4e4",
   "metadata": {},
   "source": [
    "## Trying Random Forest with Randomized Search, with feature reduced set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "347e1fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best hyper parameter: {'n_estimators': 100, 'min_samples_split': 0.1, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'gini', 'bootstrap': True}\n",
      "Best train score: 0.826038017221127\n",
      "Accuracy is:  0.8158844765342961\n",
      "Precision is:  0.8341968911917098\n",
      "Recall is:  0.8944444444444445\n",
      "f1 score is:  0.8632707774798928\n"
     ]
    }
   ],
   "source": [
    "# Run RandomizedSearchCV to tune the hyper-parameter\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier()\n",
    "k_fold_cv = 5 # Stratified 5-fold cross validation\n",
    "params = {\n",
    "    \"max_depth\" : [6,9,12,None],\n",
    " \"n_estimators\" : [10,50,100,150],\n",
    " \"max_features\" : [\"auto\", \"log2\", \"sqrt\"],\n",
    " \"bootstrap\" : [True, False],\n",
    " \"criterion\" : ['gini','entropy'],\n",
    "# \"splitter\" : ['best','random'],\n",
    " \"min_samples_split\" : [0.1,0.2,0.3,0.4,0.5]\n",
    " }\n",
    "random = RandomizedSearchCV(rfc, param_distributions=params, cv=k_fold_cv,\n",
    " n_iter = 5, scoring='accuracy',verbose=2, random_state=42,\n",
    " n_jobs=-1, return_train_score=True)\n",
    "model=random.fit(X_train, y_train)\n",
    "print('Best hyper parameter:', random.best_params_)\n",
    "print('Best train score:', random.best_score_)\n",
    "y_pred=model.predict(X_test)\n",
    "print(\"Accuracy is: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision is: \", precision_score(y_test,y_pred))\n",
    "print(\"Recall is: \", recall_score(y_test,y_pred))\n",
    "print(\"f1 score is: \", f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db3fb80",
   "metadata": {},
   "source": [
    "## After trying out several tuning approaches, it was seen that the highest accuracy was obtained when RandomForestClassifier was used(with default value for hyper parameters), and the accuracy was 0.848."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9bf9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
